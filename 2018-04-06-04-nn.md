# My first Neural Network works!

At first it just doesn't learn, so I added a commandline argument to set the learning factor eta, and it really works! Here is the history:

```
         eta last time  loss
    1                -  539998.625000
    2               50  539998.375000
    3             5000  405220.281250
    4           500000  144573.718750
    5           400000  109157.992188
    6           400000  109602.296875  <-- ???
    7           700000  109157.992188  <-- same as 5???
    7           700000   60000.000000  <-- ???
    8          7000000   60000.000000  <-- ??????
At the beginning I set the weights and biases randomly in [0,1], but when I dump the network I found that some went to [-1, 1], but some went to become a three digit one, some four, some five, even some six! I didn't read the whole dump, so maybe there are bigger ones.
    9          7000000   60000.000000  <-- I thought it is because the eta is too large that all thetas overflowed, so the network learnt nothing. So I take a smaller value in the train.
   10           700000   60000.000000
   11           700000   60000.000000
   12            70000   60000.000000  Still too large?
   13             7000   60000.000000  ... Not small enough?
   14              700   60000.000000  ... ??????????????
   15               50   60000.000000  ........
   16                1   60000.000000  something went wrong
   17               .5   60000.000000 
$ md5sum ntwkarg
2ac6ea77539f111bfe4dc543242a4ba9  ntwkarg
   18               .1   60000.000000
$ md5sum ntwkarg
2ac6ea77539f111bfe4dc543242a4ba9  ntwkarg

Why?
   19              .02   60000.000000
$ md5sum ntwkarg
0c353c76783d9fb8ab7c917e21aef6b9  ntwkarg

Changed a bit after I set this big 5000000 eta, huh!
   20          5000000  60000.000000
$ md5sum ntwkarg
441f5972b2ca9c4e3ede37c6be4462ae  ntwkarg

want more?
   20        500000000  60000.000000
   21      50000000000                  overflowed. It says "49999998976.000000"
```

Wait.... Isn't 60000 the number of the train samples? So it means I had finished training! Oh! I finally got why they take a 1/n in the loss function!

After taking the 1/n it becomes 1. But why not the final loss zero, but one?

Let's create a new network storage and train it again.

```
$ ./a.out n
Creating new network storage in "ntwkarg"
$ ./a.out e1000000
training.....................................................................
Loss: 8.999970
$ ./a.out e1000000
training.....................................................................
Loss: 1.000000
$ ./a.out e1000000
training.....................................................................
Loss: 1.000000
```

Again! Why?

```
result: 0 correct: 5
^Mtrainingresult: 0 correct: 0
^Mtrainingresult: 0 correct: 4
^Mtrainingresult: 0 correct: 1
^Mtrainingresult: 0 correct: 9
^Mtrainingresult: 0 correct: 2
^Mtrainingresult: 0 correct: 1
^Mtrainingresult: 0 correct: 3
^Mtrainingresult: 0 correct: 1
^Mtrainingresult: 0 correct: 4
^Mtrainingresult: 0 correct: 3
^Mtrainingresult: 0 correct: 5
^Mtrainingresult: 0 correct: 3
^Mtrainingresult: 0 correct: 6
^Mtrainingresult: 0 correct: 1
^Mtrainingresult: 0 correct: 7
^Mtrainingresult: 0 correct: 2
...
```

... seems the network had learnt to *cheat*! It's funny. Let's see the detail.

```
0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
```

Woo! I thought the network learnt to set the first output neuron to one and all others to zero. I was wrong. Is this because we trained too fast? Try training slowlier.

Try eta=500000. Failed.

Try eta=500. Good news: after the first train it goes to 1.00 1.00 0.33 1.00 1.00 1.00 1.00 1.00 1.00 1.00. After the second 1.00 1.00 0.00 1.00 0.70 1.00 1.00 1.00 1.00 1.00. It is strange that whatever all input images give out the same output. So there should be something wrong in the input neuron. I'll check it tomorrow.

*2018-04-07 UPDATE BELOW*

I checked the input neurons and they are good. So I tried not normalizing the input pixel (0~255) to [0,1].

```
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
training....1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
```

Yes, the same, all one-s. I thought maybe it is because the dsigmoid overflowed, since my implementation is:

```
float dsigm(float x) {
  x = exp(x);
  x = x/(1.0+x)/(1.0+x);
  if (isnan(x))
    x = 0.0;
  return x;
}
```

If I do some Mathematical thing I can make sure the middleway variables won't overflow, and it may work better.

After the update it is still all-ones. I thought maybe it is because my arguments are too big. And too large arguments also explains why every input gets the same output.

But all my initalized random arguments are in [0,1]! I'd introduce some negative ones.

Good! After introducing the negative initialized arguments, different output turned up!

```
training..............0.98 0.99 1.00 0.99 0.99 1.00 0.99 0.99 0.99 0.99 
training..............0.98 0.99 1.00 0.99 0.99 1.00 0.99 0.99 1.00 0.99 
training..............0.97 0.99 1.00 0.99 0.98 1.00 0.99 0.99 0.99 0.99 
training..............0.98 0.99 1.00 0.99 0.99 1.00 0.99 0.99 0.99 0.99 
training..............0.98 0.99 1.00 0.99 0.98 1.00 0.99 0.99 0.99 0.99 
training..............0.98 0.99 1.00 0.99 0.98 1.00 0.99 0.99 0.99 0.99 
```

But still very similar. Maybe I should use less hidden layers.

Try three layers.

```
^Mtraining1.00 0.99 0.99 0.98 0.99 0.99 1.00 0.99 0.99 0.97 
^Mtraining0.97 0.93 0.96 0.95 0.96 0.98 0.99 0.96 0.92 0.98 
^Mtraining0.99 0.98 1.00 0.99 0.99 0.99 1.00 1.00 0.96 0.98 
^Mtraining0.99 0.99 1.00 0.99 0.99 1.00 1.00 1.00 0.99 1.00 
^Mtraining0.99 0.98 1.00 0.95 0.99 0.98 1.00 0.99 0.99 0.99 
^Mtraining0.98 0.98 1.00 0.99 0.99 1.00 0.99 0.99 0.95 0.98 
^Mtraining0.99 0.98 0.99 0.99 0.99 1.00 1.00 0.97 0.98 0.99 
^Mtraining1.00 1.00 1.00 0.99 1.00 1.00 1.00 1.00 0.97 1.00 
^Mtraining0.96 0.93 1.00 0.97 0.98 0.98 0.98 0.99 0.95 0.99 
^Mtraining0.99 1.00 1.00 1.00 1.00 1.00 1.00 0.99 0.97 1.00 
^Mtraining0.99 0.99 1.00 0.99 0.99 0.99 0.99 1.00 0.98 0.97 
^Mtraining0.99 0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.97 0.99 
^Mtraining1.00 0.99 1.00 1.00 1.00 1.00 1.00 1.00 0.99 1.00 
^Mtraining1.00 0.99 1.00 1.00 1.00 1.00 1.00 1.00 0.98 1.00 
^Mtraining0.99 0.94 0.98 0.83 0.94 0.88 0.94 0.98 0.98 0.98 
```

Good! Much more different!

```
$ ./a.out n3
Creating new network storage in "ntwkarg"
$ ./a.out e500000
training.....................................................................
Loss: 8.815969
$ ./a.out e500000
training.....................................................................
Loss: 1.000000
```

```
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
^Mtraining0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 
```

Still... OMG. Let's check the hyper-parameters of Michael Nielson.

Yes my eta is too huge. Nielson wrote:

```
Suppose we try the successful 30 hidden neuron network architecture from earlier, but with the learning rate changed to Î·=100.0:

>>> net = network.Network([784, 30, 10])
>>> net.SGD(training_data, 30, 10, 100.0, test_data=test_data)

At this point we've actually gone too far, and the learning rate is too high:
Epoch 0: 1009 / 10000
Epoch 1: 1009 / 10000
Epoch 2: 1009 / 10000
Epoch 3: 1009 / 10000
...
Epoch 27: 982 / 10000
Epoch 28: 982 / 10000
Epoch 29: 982 / 10000
```

After tuning the hyper-parameter, it learns much slower:

```
$ tcc nnmnist.c -lm
$ ./a.out 
training.....................................................................
Loss: 8.993042
$ ./a.out 
training.....................................................................
Loss: 8.992221
$ ./a.out 
training.....................................................................
Loss: 8.991110
```

Let's see if it learns better:

```
^Mtraining.1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
^Mtraining.1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
^Mtraining.1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
^Mtraining.1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
^Mtraining.1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
^Mtraining.1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
^Mtraining.1.00 1.00 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 
```

ehh.. I can't see that so far.

Nielson ```after just a single epoch this has reached 9,129 out of 10,000```. Why not me??

Ten epoches later, I surprisingly found that it really learns!!!!!!!!!!

```
^Mtraining1.00 1.00 0.01 0.99 1.00 0.93 0.99 0.99 1.00 1.00 
^Mtraining1.00 1.00 0.05 0.99 1.00 0.93 1.00 0.99 1.00 0.99 
^Mtraining1.00 1.00 0.00 1.00 1.00 0.99 1.00 1.00 1.00 1.00 
^Mtraining0.99 0.98 0.01 0.97 0.99 0.91 0.90 0.96 1.00 0.99 
^Mtraining1.00 1.00 0.00 0.99 1.00 0.97 1.00 1.00 1.00 1.00 
^Mtraining1.00 1.00 0.00 0.99 1.00 0.85 0.98 1.00 1.00 0.99 
^Mtraining1.00 0.99 0.01 0.97 1.00 0.90 0.97 0.99 1.00 0.99 
^Mtraining1.00 1.00 0.00 1.00 1.00 0.96 0.99 1.00 1.00 1.00 
^Mtraining1.00 1.00 0.02 1.00 0.99 0.87 0.99 1.00 1.00 0.99 
^Mtraining0.98 0.99 0.03 0.97 1.00 0.95 0.97 0.98 1.00 0.99 
^Mtraining1.00 1.00 0.07 0.99 0.99 0.97 0.99 1.00 1.00 1.00 
^Mtraining1.00 1.00 0.12 1.00 1.00 0.99 1.00 1.00 1.00 1.00
```

You can see that some neurons became nearly zero, but some not!

But how could Nielson get 9,129 out of 10,000 after just a single epoch?

```
$ for i in {1..30}; do ./a.out; done
training.....................................................................
Loss: 7.885902
training.....................................................................
Loss: 7.074048
training.....................................................................
Loss: 5.762972
training.....................................................................
Loss: 4.411054
training.....................................................................
Loss: 3.007590
training.....................................................................
Loss: 1.295312
training.....................................................................
Loss: 0.990557
training.....................................................................
Loss: 0.949183
training.....................................................................
Loss: 0.933607
training.....................................................................
Loss: 0.925593
training.....................................................................
Loss: 0.920352
training.....................................................................
Loss: 0.916346
training.....................................................................
Loss: 0.913481
training.....................................................................
Loss: 0.910749
training.....................................................................
Loss: 0.908519
training.....................................................................
Loss: 0.906225
training.....................................................................
Loss: 0.904084
training.....................................................................
Loss: 0.902312
training.....................................................................
Loss: 0.900112
training.....................................................................
Loss: 0.898339
training.....................................................................
Loss: 0.896395
training.....................................................................
Loss: 0.894435
training.....................................................................
Loss: 0.892398
training.....................................................................
Loss: 0.890426
training.....................................................................
Loss: 0.887986
training.....................................................................
Loss: 0.885743
training.....................................................................
Loss: 0.883692
training.....................................................................
Loss: 0.881237
training.....................................................................
Loss: 0.878811
training.....................................................................
Loss: 0.875969
```

It finally continues to learn after reaching loss=1! But slowly. Let's see how it learnt:

```
^Mtraining0.17 0.07 0.11 0.11 0.07 0.06 0.08 0.10 0.06 0.06 
^Mtraining0.48 0.30 0.00 0.05 0.42 0.04 0.16 0.49 0.31 0.18 
^Mtraining0.07 0.14 0.06 0.08 0.06 0.07 0.10 0.07 0.04 0.06 
^Mtraining0.08 0.06 0.05 0.07 0.14 0.06 0.06 0.10 0.05 0.15 
^Mtraining0.08 0.09 0.10 0.10 0.09 0.09 0.09 0.08 0.04 0.09 
^Mtraining0.10 0.20 0.08 0.06 0.13 0.07 0.07 0.14 0.06 0.09 
^Mtraining0.08 0.09 0.10 0.10 0.09 0.09 0.09 0.08 0.04 0.09 
^Mtraining0.06 0.37 0.10 0.08 0.15 0.09 0.15 0.14 0.07 0.10 
^Mtraining0.11 0.28 0.07 0.09 0.11 0.11 0.11 0.14 0.07 0.11 
^Mtraining0.08 0.09 0.10 0.10 0.09 0.09 0.09 0.08 0.04 0.09 
^Mtraining0.20 0.36 0.09 0.16 0.09 0.11 0.20 0.21 0.06 0.06 
```

Good! It works! Now let's learn more.

I'll later figure out why Nielson got 91% after one single epoch but not me.
